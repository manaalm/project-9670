{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 - Summary Report\n",
    "\n",
    "This notebook compiles all results and generates the final summary for the project:\n",
    "\n",
    "**\"When Geometry Fails: Stress-Testing Git Re-Basin on Spurious vs Robust Features\"**\n",
    "\n",
    "## Core Hypothesis (Recap):\n",
    "Permutation alignment (Git Re-Basin) can successfully connect models relying on the same feature type, but fails to connect models with mismatched mechanisms (spurious vs robust), producing measurable loss and semantic barriers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from src.config import (\n",
    "    get_config, RESULTS_DIR, FIGURES_DIR, METRICS_DIR\n",
    ")\n",
    "from src.plotting import save_figure\n",
    "\n",
    "config = get_config()\n",
    "print(f\"Loading results from: {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all saved metrics\n",
    "results = {}\n",
    "\n",
    "# Training summary\n",
    "training_path = METRICS_DIR / 'training_summary.json'\n",
    "if training_path.exists():\n",
    "    with open(training_path, 'r') as f:\n",
    "        results['training'] = json.load(f)\n",
    "    print(f\"Loaded training summary\")\n",
    "\n",
    "# Mechanism verification\n",
    "mechanism_path = METRICS_DIR / 'mechanism_verification.json'\n",
    "if mechanism_path.exists():\n",
    "    with open(mechanism_path, 'r') as f:\n",
    "        results['mechanism'] = json.load(f)\n",
    "    print(f\"Loaded mechanism verification results\")\n",
    "\n",
    "# Rebasin results\n",
    "rebasin_path = METRICS_DIR / 'rebasin_results.json'\n",
    "if rebasin_path.exists():\n",
    "    with open(rebasin_path, 'r') as f:\n",
    "        results['rebasin'] = json.load(f)\n",
    "    print(f\"Loaded rebasin results\")\n",
    "\n",
    "# Interpolation summary\n",
    "summary_path = RESULTS_DIR / 'summary.json'\n",
    "if summary_path.exists():\n",
    "    with open(summary_path, 'r') as f:\n",
    "        results['interpolation'] = json.load(f)\n",
    "    print(f\"Loaded interpolation summary\")\n",
    "\n",
    "print(f\"\\nLoaded {len(results)} result files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'mechanism' in results:\n",
    "    srs_results = results['mechanism']['srs_results']\n",
    "    \n",
    "    # Create performance table\n",
    "    performance_data = []\n",
    "    for model_name in ['A1', 'A2', 'R1', 'R2']:\n",
    "        if model_name in srs_results:\n",
    "            m = srs_results[model_name]\n",
    "            model_type = 'Spurious' if model_name.startswith('A') else 'Robust'\n",
    "            performance_data.append({\n",
    "                'Model': model_name,\n",
    "                'Type': model_type,\n",
    "                'ID Acc (%)': f\"{m['id_accuracy']*100:.1f}\",\n",
    "                'OOD Acc (%)': f\"{m['ood_accuracy']*100:.1f}\",\n",
    "                'OOD Drop (%)': f\"{m['ood_drop']*100:.1f}\",\n",
    "                'SRS': f\"{m['spurious_reliance_score']:.4f}\",\n",
    "            })\n",
    "    \n",
    "    df_performance = pd.DataFrame(performance_data)\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"MODEL PERFORMANCE SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(df_performance.to_string(index=False))\n",
    "else:\n",
    "    print(\"[WARNING] Mechanism verification results not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Git Re-Basin Effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'rebasin' in results:\n",
    "    comparison = results['rebasin']['comparison']\n",
    "    \n",
    "    rebasin_data = []\n",
    "    for pair_name, data in comparison.items():\n",
    "        rebasin_data.append({\n",
    "            'Pair': pair_name,\n",
    "            'Type': data['type'],\n",
    "            'Pre Cosine Sim': f\"{data['pre_cosine_sim']:.4f}\",\n",
    "            'Post Cosine Sim': f\"{data['post_cosine_sim']:.4f}\",\n",
    "            'Change': f\"{data['cosine_sim_change']:+.4f}\",\n",
    "            'Pre Agreement (%)': f\"{data['pre_agreement']*100:.1f}\",\n",
    "            'Post Agreement (%)': f\"{data['post_agreement']*100:.1f}\",\n",
    "        })\n",
    "    \n",
    "    df_rebasin = pd.DataFrame(rebasin_data)\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\"GIT RE-BASIN EFFECTIVENESS\")\n",
    "    print(\"=\"*90)\n",
    "    print(df_rebasin.to_string(index=False))\n",
    "else:\n",
    "    print(\"[WARNING] Rebasin results not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Barrier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'interpolation' in results and 'barrier_comparison' in results['interpolation']:\n",
    "    barriers = results['interpolation']['barrier_comparison']\n",
    "    \n",
    "    barrier_data = []\n",
    "    for pair_name, data in barriers.items():\n",
    "        barrier_data.append({\n",
    "            'Pair': pair_name,\n",
    "            'Type': data['type'],\n",
    "            'Pre ID Barrier': f\"{data['pre_id_loss_barrier']:.4f}\",\n",
    "            'Post ID Barrier': f\"{data.get('post_id_loss_barrier', float('nan')):.4f}\",\n",
    "            'Pre OOD Barrier': f\"{data['pre_ood_loss_barrier']:.4f}\",\n",
    "            'Post OOD Barrier': f\"{data.get('post_ood_loss_barrier', float('nan')):.4f}\",\n",
    "        })\n",
    "    \n",
    "    df_barriers = pd.DataFrame(barrier_data)\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\"LOSS BARRIER ANALYSIS\")\n",
    "    print(\"=\"*90)\n",
    "    print(df_barriers.to_string(index=False))\n",
    "    \n",
    "    # Compute statistics\n",
    "    same_mech = [barriers[p]['post_id_loss_barrier'] for p in ['A1-A2', 'R1-R2'] \n",
    "                 if 'post_id_loss_barrier' in barriers.get(p, {})]\n",
    "    diff_mech = [barriers[p]['post_id_loss_barrier'] for p in ['A1-R1'] \n",
    "                 if 'post_id_loss_barrier' in barriers.get(p, {})]\n",
    "    \n",
    "    if same_mech and diff_mech:\n",
    "        print(f\"\\nKey Statistics:\")\n",
    "        print(f\"  Same-mechanism pairs avg barrier: {np.mean(same_mech):.4f}\")\n",
    "        print(f\"  Diff-mechanism pair barrier:      {np.mean(diff_mech):.4f}\")\n",
    "        print(f\"  Ratio (diff/same):                {np.mean(diff_mech)/np.mean(same_mech):.2f}x\")\n",
    "else:\n",
    "    print(\"[WARNING] Interpolation results not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Semantic Barrier (SRS Variation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'interpolation' in results and 'srs_interpolation' in results['interpolation']:\n",
    "    srs_interp = results['interpolation']['srs_interpolation']\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SEMANTIC BARRIER ANALYSIS (A1-R1 Interpolation)\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nSRS at endpoints:\")\n",
    "    print(f\"  A1 (spurious, alpha=1): {srs_interp['srs_values'][-1]:.4f}\")\n",
    "    print(f\"  R1 (robust, alpha=0):   {srs_interp['srs_values'][0]:.4f}\")\n",
    "    print(f\"\\nSemantic barrier metric:\")\n",
    "    print(f\"  Max SRS variation: {srs_interp['semantic_barrier']:.4f}\")\n",
    "    print(f\"  At alpha:          {srs_interp['semantic_barrier_alpha']:.2f}\")\n",
    "    \n",
    "    # Plot SRS along path\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    alphas = srs_interp['alphas']\n",
    "    srs_vals = srs_interp['srs_values']\n",
    "    \n",
    "    ax.plot(alphas, srs_vals, 'purple', linewidth=2, marker='o', markersize=8)\n",
    "    ax.axhline(y=srs_vals[0], color='blue', linestyle='--', alpha=0.5, label='R1 (robust)')\n",
    "    ax.axhline(y=srs_vals[-1], color='red', linestyle='--', alpha=0.5, label='A1 (spurious)')\n",
    "    ax.set_xlabel(r'$\\alpha$ (0=R1, 1=A1)', fontsize=12)\n",
    "    ax.set_ylabel('Spurious Reliance Score', fontsize=12)\n",
    "    ax.set_title('Semantic Barrier: SRS Along A1-R1 Interpolation', fontsize=14)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Annotate endpoints\n",
    "    ax.annotate('Robust\\n(low SRS)', xy=(0, srs_vals[0]), xytext=(0.15, srs_vals[0]-0.05),\n",
    "                fontsize=10, ha='center')\n",
    "    ax.annotate('Spurious\\n(high SRS)', xy=(1, srs_vals[-1]), xytext=(0.85, srs_vals[-1]+0.05),\n",
    "                fontsize=10, ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_figure(fig, 'semantic_barrier_summary')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"[WARNING] SRS interpolation results not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Final Summary Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive summary figure\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "\n",
    "# Panel 1: Model performance comparison\n",
    "ax1 = fig.add_subplot(2, 2, 1)\n",
    "if 'mechanism' in results:\n",
    "    srs = results['mechanism']['srs_results']\n",
    "    models = ['A1', 'A2', 'R1', 'R2']\n",
    "    x = np.arange(len(models))\n",
    "    width = 0.35\n",
    "    \n",
    "    id_accs = [srs[m]['id_accuracy']*100 for m in models]\n",
    "    ood_accs = [srs[m]['ood_accuracy']*100 for m in models]\n",
    "    \n",
    "    ax1.bar(x - width/2, id_accs, width, label='ID Acc', color='steelblue')\n",
    "    ax1.bar(x + width/2, ood_accs, width, label='OOD Acc', color='coral')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(models)\n",
    "    ax1.set_ylabel('Accuracy (%)')\n",
    "    ax1.set_title('(A) Model Performance: ID vs OOD')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Panel 2: SRS comparison\n",
    "ax2 = fig.add_subplot(2, 2, 2)\n",
    "if 'mechanism' in results:\n",
    "    srs_vals = [srs[m]['spurious_reliance_score'] for m in models]\n",
    "    colors = ['#e74c3c', '#e67e22', '#3498db', '#2ecc71']\n",
    "    bars = ax2.bar(x, srs_vals, color=colors)\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(models)\n",
    "    ax2.set_ylabel('Spurious Reliance Score')\n",
    "    ax2.set_title('(B) Spurious Reliance Score by Model')\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add horizontal line separating spurious vs robust\n",
    "    avg_srs = np.mean(srs_vals)\n",
    "    ax2.axhline(y=avg_srs, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Panel 3: Barrier comparison\n",
    "ax3 = fig.add_subplot(2, 2, 3)\n",
    "if 'interpolation' in results and 'barrier_comparison' in results['interpolation']:\n",
    "    barriers = results['interpolation']['barrier_comparison']\n",
    "    pairs = list(barriers.keys())\n",
    "    x = np.arange(len(pairs))\n",
    "    width = 0.35\n",
    "    \n",
    "    pre = [barriers[p]['pre_id_loss_barrier'] for p in pairs]\n",
    "    post = [barriers[p].get('post_id_loss_barrier', 0) for p in pairs]\n",
    "    \n",
    "    ax3.bar(x - width/2, pre, width, label='Pre-Rebasin', color='salmon')\n",
    "    ax3.bar(x + width/2, post, width, label='Post-Rebasin', color='steelblue')\n",
    "    ax3.set_xticks(x)\n",
    "    ax3.set_xticklabels(pairs)\n",
    "    ax3.set_ylabel('Loss Barrier')\n",
    "    ax3.set_title('(C) Loss Barriers: Pre vs Post Re-Basin')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Panel 4: Key finding - barrier ratio\n",
    "ax4 = fig.add_subplot(2, 2, 4)\n",
    "if 'interpolation' in results and 'barrier_comparison' in results['interpolation']:\n",
    "    barriers = results['interpolation']['barrier_comparison']\n",
    "    \n",
    "    # Get post-rebasin barriers\n",
    "    same_mech_barriers = [barriers[p].get('post_id_loss_barrier', barriers[p]['pre_id_loss_barrier']) \n",
    "                         for p in ['A1-A2', 'R1-R2']]\n",
    "    diff_mech_barrier = barriers['A1-R1'].get('post_id_loss_barrier', barriers['A1-R1']['pre_id_loss_barrier'])\n",
    "    \n",
    "    categories = ['Same\\nMechanism', 'Different\\nMechanism']\n",
    "    values = [np.mean(same_mech_barriers), diff_mech_barrier]\n",
    "    colors = ['#2ecc71', '#e74c3c']\n",
    "    \n",
    "    bars = ax4.bar(categories, values, color=colors, edgecolor='black', linewidth=2)\n",
    "    ax4.set_ylabel('Post-Rebasin Loss Barrier')\n",
    "    ax4.set_title('(D) Key Finding: Mechanism Mismatch = Higher Barrier')\n",
    "    ax4.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, val in zip(bars, values):\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                f'{val:.4f}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Add ratio annotation\n",
    "    if values[0] > 0:\n",
    "        ratio = values[1] / values[0]\n",
    "        ax4.text(0.5, max(values) * 0.5, f'Ratio: {ratio:.1f}x', ha='center', fontsize=14,\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.suptitle('When Geometry Fails: Git Re-Basin on Spurious vs Robust Features', \n",
    "             fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "save_figure(fig, 'final_summary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Key Findings for Blog Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY FINDINGS FOR CLASS BLOG\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "findings = []\n",
    "\n",
    "# Finding 1: Spurious models rely on patches\n",
    "if 'mechanism' in results:\n",
    "    srs = results['mechanism']['srs_results']\n",
    "    spurious_srs = np.mean([srs['A1']['spurious_reliance_score'], srs['A2']['spurious_reliance_score']])\n",
    "    robust_srs = np.mean([srs['R1']['spurious_reliance_score'], srs['R2']['spurious_reliance_score']])\n",
    "    \n",
    "    findings.append(\n",
    "        f\"1. **Spurious Feature Reliance**: Models trained on spurious-aligned data (A1, A2) \"\n",
    "        f\"show {spurious_srs/robust_srs:.1f}x higher Spurious Reliance Score than robust models (R1, R2), \"\n",
    "        f\"confirming they learn to rely on the colored patch shortcut.\"\n",
    "    )\n",
    "\n",
    "# Finding 2: OOD accuracy gap\n",
    "if 'mechanism' in results:\n",
    "    spurious_ood_drop = np.mean([srs['A1']['ood_drop'], srs['A2']['ood_drop']]) * 100\n",
    "    robust_ood_drop = np.mean([srs['R1']['ood_drop'], srs['R2']['ood_drop']]) * 100\n",
    "    \n",
    "    findings.append(\n",
    "        f\"2. **OOD Generalization Gap**: Spurious models suffer {spurious_ood_drop:.1f}% accuracy drop \"\n",
    "        f\"when patches are removed, while robust models only drop {robust_ood_drop:.1f}%.\"\n",
    "    )\n",
    "\n",
    "# Finding 3: Rebasin reduces barriers\n",
    "if 'rebasin' in results:\n",
    "    comp = results['rebasin']['comparison']\n",
    "    avg_sim_increase = np.mean([comp[p]['cosine_sim_change'] for p in comp])\n",
    "    \n",
    "    findings.append(\n",
    "        f\"3. **Git Re-Basin Works**: Weight matching increases cosine similarity by \"\n",
    "        f\"{avg_sim_increase:+.4f} on average, enabling more meaningful weight interpolation.\"\n",
    "    )\n",
    "\n",
    "# Finding 4: Different mechanisms = higher barriers\n",
    "if 'interpolation' in results and 'barrier_comparison' in results['interpolation']:\n",
    "    barriers = results['interpolation']['barrier_comparison']\n",
    "    same_mech = np.mean([barriers[p].get('post_id_loss_barrier', barriers[p]['pre_id_loss_barrier']) \n",
    "                        for p in ['A1-A2', 'R1-R2']])\n",
    "    diff_mech = barriers['A1-R1'].get('post_id_loss_barrier', barriers['A1-R1']['pre_id_loss_barrier'])\n",
    "    \n",
    "    findings.append(\n",
    "        f\"4. **Geometry Fails for Mechanism Mismatch**: Even after Re-Basin, spurious-robust pairs \"\n",
    "        f\"have {diff_mech/same_mech:.1f}x higher loss barriers than same-mechanism pairs, \"\n",
    "        f\"indicating that geometric alignment cannot bridge semantic differences.\"\n",
    "    )\n",
    "\n",
    "# Finding 5: Semantic barrier\n",
    "if 'interpolation' in results and 'srs_interpolation' in results['interpolation']:\n",
    "    srs_interp = results['interpolation']['srs_interpolation']\n",
    "    \n",
    "    findings.append(\n",
    "        f\"5. **Semantic Barrier Evidence**: Along the A1-R1 interpolation path, SRS varies from \"\n",
    "        f\"{srs_interp['srs_values'][0]:.3f} (robust) to {srs_interp['srs_values'][-1]:.3f} (spurious), \"\n",
    "        f\"demonstrating that intermediate models inherit inconsistent feature dependencies.\"\n",
    "    )\n",
    "\n",
    "# Print findings\n",
    "for finding in findings:\n",
    "    print(f\"\\n{finding}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional findings\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ADDITIONAL INSIGHTS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "additional = [\n",
    "    \"6. **Same-Mechanism Connectivity**: Models sharing the same feature dependency \"\n",
    "    \"(both spurious or both robust) can be smoothly interpolated after Re-Basin, \"\n",
    "    \"with minimal loss barriers along the path.\",\n",
    "    \n",
    "    \"7. **Practical Implication**: Before merging or ensembling models, practitioners should \"\n",
    "    \"verify that models rely on similar features. Geometric tools like Re-Basin cannot fix \"\n",
    "    \"fundamental differences in what models have learned.\",\n",
    "    \n",
    "    \"8. **Future Directions**: This work suggests that loss barrier analysis post-Re-Basin \"\n",
    "    \"could serve as a diagnostic tool for detecting when models have learned qualitatively \"\n",
    "    \"different solutions to the same task.\",\n",
    "]\n",
    "\n",
    "for insight in additional:\n",
    "    print(f\"\\n{insight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile final summary\n",
    "final_report = {\n",
    "    'project_title': 'When Geometry Fails: Stress-Testing Git Re-Basin on Spurious vs Robust Features',\n",
    "    'hypothesis': 'Permutation alignment (Git Re-Basin) can successfully connect models relying on the same feature type, but fails to connect models with mismatched mechanisms.',\n",
    "    'key_findings': findings,\n",
    "    'additional_insights': additional,\n",
    "}\n",
    "\n",
    "# Add numerical results if available\n",
    "if 'mechanism' in results:\n",
    "    final_report['model_performance'] = results['mechanism']['srs_results']\n",
    "    final_report['group_statistics'] = results['mechanism']['group_statistics']\n",
    "\n",
    "if 'interpolation' in results and 'barrier_comparison' in results['interpolation']:\n",
    "    final_report['barrier_analysis'] = results['interpolation']['barrier_comparison']\n",
    "\n",
    "# Save final report\n",
    "report_path = RESULTS_DIR / 'final_report.json'\n",
    "with open(report_path, 'w') as f:\n",
    "    json.dump(final_report, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\nFinal report saved to: {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. List All Generated Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ALL GENERATED OUTPUTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nCheckpoints (results/checkpoints/):\")\n",
    "from src.config import CHECKPOINTS_DIR\n",
    "for f in sorted(CHECKPOINTS_DIR.glob('*.pt')):\n",
    "    print(f\"  - {f.name}\")\n",
    "\n",
    "print(\"\\nFigures (results/figures/):\")\n",
    "for f in sorted(FIGURES_DIR.glob('*.png')):\n",
    "    print(f\"  - {f.name}\")\n",
    "\n",
    "print(\"\\nMetrics (results/metrics/):\")\n",
    "for f in sorted(METRICS_DIR.glob('*.json')):\n",
    "    print(f\"  - {f.name}\")\n",
    "\n",
    "print(\"\\nSummary files (results/):\")\n",
    "for f in sorted(RESULTS_DIR.glob('*.json')):\n",
    "    if f.parent == RESULTS_DIR:  # Only top-level\n",
    "        print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXPERIMENT COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "This experiment demonstrated that:\n",
    "\n",
    "1. Git Re-Basin (weight matching) successfully aligns models in weight space,\n",
    "   increasing cosine similarity and reducing pre-rebasin loss barriers.\n",
    "\n",
    "2. However, when models rely on fundamentally different features (spurious vs\n",
    "   robust), significant barriers remain even after alignment.\n",
    "\n",
    "3. The \"semantic barrier\" - measured by Spurious Reliance Score variation\n",
    "   along the interpolation path - reveals mechanism mismatch that pure\n",
    "   geometric methods cannot resolve.\n",
    "\n",
    "4. This has practical implications for model merging, ensembling, and\n",
    "   understanding the structure of loss landscapes.\n",
    "\n",
    "Key Takeaway:\n",
    "-------------\n",
    "Geometry (permutation alignment) is necessary but not sufficient for\n",
    "meaningful model interpolation. Models must also share similar learned\n",
    "representations and feature dependencies.\n",
    "\n",
    "\"When geometry fails, it's because the models have learned to see\n",
    "the world in fundamentally different ways.\"\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
