{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 - Setup and Configuration\n",
    "\n",
    "This notebook sets up the environment for the Git Re-Basin spurious features experiment.\n",
    "\n",
    "## What this notebook does:\n",
    "1. Validates all dependencies are installed\n",
    "2. Defines the global CONFIG dictionary\n",
    "3. Sets deterministic seeds for reproducibility\n",
    "4. Creates necessary directories\n",
    "5. Verifies GPU availability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Add src to path and validate imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate core dependencies\n",
    "import importlib\n",
    "\n",
    "dependencies = [\n",
    "    ('torch', 'PyTorch'),\n",
    "    ('torchvision', 'TorchVision'),\n",
    "    ('numpy', 'NumPy'),\n",
    "    ('scipy', 'SciPy'),\n",
    "    ('sklearn', 'Scikit-learn'),\n",
    "    ('matplotlib', 'Matplotlib'),\n",
    "    ('seaborn', 'Seaborn'),\n",
    "    ('tqdm', 'tqdm'),\n",
    "    ('PIL', 'Pillow'),\n",
    "]\n",
    "\n",
    "print(\"Checking dependencies...\\n\")\n",
    "all_ok = True\n",
    "\n",
    "for module_name, display_name in dependencies:\n",
    "    try:\n",
    "        module = importlib.import_module(module_name)\n",
    "        version = getattr(module, '__version__', 'unknown')\n",
    "        print(f\"  [OK] {display_name}: {version}\")\n",
    "    except ImportError:\n",
    "        print(f\"  [MISSING] {display_name}\")\n",
    "        all_ok = False\n",
    "\n",
    "if all_ok:\n",
    "    print(\"\\nAll dependencies are installed!\")\n",
    "else:\n",
    "    print(\"\\nSome dependencies are missing. Run: pip install -r requirements.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate src module imports\n",
    "print(\"Checking src modules...\\n\")\n",
    "\n",
    "src_modules = ['config', 'data', 'models', 'train', 'rebasin', 'interp', 'metrics', 'plotting']\n",
    "\n",
    "for module_name in src_modules:\n",
    "    try:\n",
    "        module = importlib.import_module(f'src.{module_name}')\n",
    "        print(f\"  [OK] src.{module_name}\")\n",
    "    except ImportError as e:\n",
    "        print(f\"  [ERROR] src.{module_name}: {e}\")\n",
    "\n",
    "print(\"\\nAll src modules loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import get_config, CONFIG, set_seed, get_device, setup_directories\n",
    "\n",
    "# Load configuration\n",
    "config = get_config()\n",
    "\n",
    "print(\"Global Configuration:\")\n",
    "print(\"=\" * 50)\n",
    "for section, values in config.items():\n",
    "    print(f\"\\n[{section}]\")\n",
    "    if isinstance(values, dict):\n",
    "        for key, val in values.items():\n",
    "            print(f\"  {key}: {val}\")\n",
    "    else:\n",
    "        print(f\"  {values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set Deterministic Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Set global seed\n",
    "GLOBAL_SEED = config['seeds']['global']\n",
    "set_seed(GLOBAL_SEED)\n",
    "\n",
    "print(f\"Global seed set to: {GLOBAL_SEED}\")\n",
    "print(f\"\\nModel seeds:\")\n",
    "print(f\"  Model A1 (spurious): {config['seeds']['model_A1']}\")\n",
    "print(f\"  Model A2 (spurious): {config['seeds']['model_A2']}\")\n",
    "print(f\"  Model R1 (robust):   {config['seeds']['model_R1']}\")\n",
    "print(f\"  Model R2 (robust):   {config['seeds']['model_R2']}\")\n",
    "\n",
    "# Verify determinism\n",
    "print(f\"\\nDeterminism settings:\")\n",
    "print(f\"  torch.backends.cudnn.deterministic: {torch.backends.cudnn.deterministic}\")\n",
    "print(f\"  torch.backends.cudnn.benchmark: {torch.backends.cudnn.benchmark}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all necessary directories\n",
    "dirs = setup_directories()\n",
    "\n",
    "print(\"Directory structure:\")\n",
    "for name, path in dirs.items():\n",
    "    exists = \"[EXISTS]\" if path.exists() else \"[CREATED]\"\n",
    "    print(f\"  {exists} {name}: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Check Device (GPU/CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_device()\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(f\"\\nCUDA Details:\")\n",
    "    print(f\"  Device name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"  Memory allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
    "    print(f\"  Memory reserved: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")\n",
    "elif device.type == 'mps':\n",
    "    print(f\"\\nUsing Apple Metal Performance Shaders (MPS)\")\n",
    "else:\n",
    "    print(f\"\\nNo GPU available, using CPU. Training will be slower.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Quick Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that we can create a model and do a forward pass\n",
    "from src.models import create_model, count_parameters\n",
    "\n",
    "model = create_model(config)\n",
    "model = model.to(device)\n",
    "\n",
    "# Create dummy input\n",
    "dummy_input = torch.randn(2, 3, 32, 32).to(device)\n",
    "output = model(dummy_input)\n",
    "\n",
    "print(\"Model sanity check:\")\n",
    "print(f\"  Model architecture: {config['model']['architecture']}\")\n",
    "print(f\"  Parameters: {count_parameters(model):,}\")\n",
    "print(f\"  Input shape: {dummy_input.shape}\")\n",
    "print(f\"  Output shape: {output.shape}\")\n",
    "print(f\"  Forward pass: OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data loading\n",
    "from src.data import create_env_a_dataset, create_no_patch_dataset\n",
    "\n",
    "print(\"Testing data loading...\")\n",
    "\n",
    "# This will download CIFAR-10 if not present\n",
    "env_a_train = create_env_a_dataset(train=True, config=config)\n",
    "env_a_test = create_env_a_dataset(train=False, config=config)\n",
    "no_patch_test = create_no_patch_dataset(train=False, config=config)\n",
    "\n",
    "print(f\"\\nDataset sizes:\")\n",
    "print(f\"  Env A train: {len(env_a_train)}\")\n",
    "print(f\"  Env A test (ID): {len(env_a_test)}\")\n",
    "print(f\"  No patch test (OOD): {len(no_patch_test)}\")\n",
    "\n",
    "# Verify alignment rate\n",
    "alignment_rate = env_a_train.get_alignment_rate()\n",
    "expected_rate = config['patch']['p_align_env_a']\n",
    "print(f\"\\nEnv A alignment rate: {alignment_rate:.3f} (expected: {expected_rate})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"SETUP COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\"\"\n",
    "Environment:\n",
    "  - Device: {device}\n",
    "  - Global seed: {GLOBAL_SEED}\n",
    "  - All dependencies: OK\n",
    "  - All src modules: OK\n",
    "  - Directory structure: OK\n",
    "\n",
    "Configuration:\n",
    "  - Dataset: {config['data']['dataset']}\n",
    "  - Patch size: {config['patch']['size']}x{config['patch']['size']}\n",
    "  - Env A alignment: {config['patch']['p_align_env_a']}\n",
    "  - Env B alignment: {config['patch']['p_align_env_b']}\n",
    "  - Model: {config['model']['architecture']}\n",
    "  - Training epochs: {config['training']['num_epochs']}\n",
    "  - Batch size: {config['training']['batch_size']}\n",
    "\n",
    "Next steps:\n",
    "  1. Run 01_data_spurious_envs.ipynb to visualize datasets\n",
    "  2. Run 02_train_models.ipynb to train all 4 models\n",
    "  3. Continue with remaining notebooks in order\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save config to results for reference\n",
    "import json\n",
    "from src.config import RESULTS_DIR\n",
    "\n",
    "config_path = RESULTS_DIR / 'config.json'\n",
    "\n",
    "# Convert config to JSON-serializable format\n",
    "config_json = {}\n",
    "for key, value in config.items():\n",
    "    if isinstance(value, dict):\n",
    "        config_json[key] = {}\n",
    "        for k, v in value.items():\n",
    "            if isinstance(v, (list, tuple)):\n",
    "                config_json[key][k] = list(v)\n",
    "            else:\n",
    "                config_json[key][k] = v\n",
    "    else:\n",
    "        config_json[key] = value\n",
    "\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(config_json, f, indent=2)\n",
    "\n",
    "print(f\"Configuration saved to: {config_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
