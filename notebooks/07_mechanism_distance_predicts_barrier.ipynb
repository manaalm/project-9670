{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 07 - Mechanism Distance Predicts Barrier Height\n",
    "\n",
    "This notebook tests the hypothesis that **linear interpolation barrier height is predictable from \"mechanism distance\"** between two endpoint models.\n",
    "\n",
    "## Research Question\n",
    "Can we predict how well Git Re-Basin will work (low barrier) based on how similar the models' learned mechanisms are?\n",
    "\n",
    "## Mechanism Distance Metrics\n",
    "1. **Cue-Reliance Distance (dist_srs)**: Absolute difference in Spurious Reliance Score\n",
    "   - `dist_srs = |SRS(A) - SRS(B)|`\n",
    "   - Models with similar spurious reliance should have similar mechanisms\n",
    "\n",
    "2. **Representation Distance (dist_cka)**: CKA-based feature similarity\n",
    "   - `dist_cka = 1 - mean(CKA)` across layers\n",
    "   - Models with similar internal representations should have similar mechanisms\n",
    "\n",
    "## Analysis Plan\n",
    "1. Load all model pairs (S-S, R-R, S-R)\n",
    "2. Compute mechanism distance metrics for each pair\n",
    "3. Retrieve barrier heights (pre and post rebasin)\n",
    "4. Correlate mechanism distance with barrier height\n",
    "5. Fit regression: barrier ~ dist_srs + dist_cka\n",
    "6. Generate publication-quality figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from src.config import (\n",
    "    get_config, set_seed, get_device,\n",
    "    CHECKPOINTS_DIR, FIGURES_DIR, METRICS_DIR, RESULTS_DIR\n",
    ")\n",
    "\n",
    "# Set style for publication-quality figures\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.titlesize'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 11\n",
    "\n",
    "config = get_config()\n",
    "set_seed(config['seeds']['global'])\n",
    "device = get_device()\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import project modules\n",
    "from src.data import (\n",
    "    create_env_a_dataset,\n",
    "    create_no_patch_dataset,\n",
    "    CounterfactualPatchDataset,\n",
    ")\n",
    "from src.models import create_model\n",
    "from src.train import load_model\n",
    "from src.interp import evaluate_interpolation_multi_dataset\n",
    "from src.metrics import (\n",
    "    compute_spurious_reliance_score,\n",
    "    compute_srs_distance,\n",
    "    get_srs_scalar,\n",
    "    compute_all_barriers,\n",
    "    bootstrap_correlation,\n",
    "    fit_linear_regression,\n",
    ")\n",
    "from src.cka import (\n",
    "    compute_cka_distance,\n",
    "    compute_layerwise_cka,\n",
    "    create_cka_dataloader,\n",
    "    compute_singular_vector_alignment,\n",
    ")\n",
    "from src.pairs import (\n",
    "    get_standard_pairs,\n",
    "    load_model_pair,\n",
    "    load_all_standard_pairs,\n",
    "    get_pair_short_name,\n",
    "    check_checkpoints_exist,\n",
    "    print_checkpoint_status,\n",
    "    PAIR_TYPE_SS, PAIR_TYPE_RR, PAIR_TYPE_SR,\n",
    ")\n",
    "from src.plotting import save_figure\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 1. Check Prerequisites and Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what checkpoints are available\n",
    "print(\"Checking checkpoint availability...\\n\")\n",
    "print_checkpoint_status()\n",
    "\n",
    "# Verify required checkpoints exist\n",
    "status = check_checkpoints_exist()\n",
    "required = ['A1', 'A2', 'R1', 'R2']\n",
    "missing = [m for m in required if not status.get(m, False)]\n",
    "if missing:\n",
    "    raise FileNotFoundError(\n",
    "        f\"Missing required checkpoints: {missing}\\n\"\n",
    "        f\"Please run notebooks 02-04 first.\"\n",
    "    )\n",
    "print(\"\\nAll required checkpoints found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all model pairs\n",
    "print(\"Loading model pairs...\\n\")\n",
    "model_pairs = load_all_standard_pairs(device, config, load_aligned=True)\n",
    "\n",
    "for name, pair in model_pairs.items():\n",
    "    aligned_status = \"Yes\" if pair.model_b_aligned is not None else \"No\"\n",
    "    print(f\"  {name}: type={pair.pair_type}, aligned={aligned_status}\")\n",
    "\n",
    "print(f\"\\nLoaded {len(model_pairs)} model pairs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 2. Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test datasets\n",
    "test_id = create_env_a_dataset(train=False, config=config)\n",
    "test_ood = create_no_patch_dataset(train=False, config=config)\n",
    "\n",
    "batch_size = config['interpolation']['eval_batch_size']\n",
    "num_workers = config['training']['num_workers']\n",
    "\n",
    "id_loader = DataLoader(test_id, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "ood_loader = DataLoader(test_ood, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "dataloaders = {\n",
    "    'id': id_loader,\n",
    "    'ood': ood_loader,\n",
    "}\n",
    "\n",
    "print(f\"Test datasets: ID={len(test_id)}, OOD={len(test_ood)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create counterfactual dataset for SRS computation\n",
    "cf_dataset = CounterfactualPatchDataset(\n",
    "    base_dataset=test_id,\n",
    "    swap_mode='random_wrong',\n",
    ")\n",
    "\n",
    "# Create fixed CKA dataloader (using subset for efficiency)\n",
    "CKA_N_SAMPLES = 2000  # Configurable number of samples for CKA\n",
    "cka_loader = create_cka_dataloader(\n",
    "    test_id, \n",
    "    n_samples=CKA_N_SAMPLES, \n",
    "    batch_size=batch_size,\n",
    "    seed=config['seeds']['global'],\n",
    ")\n",
    "\n",
    "print(f\"Counterfactual dataset: {len(cf_dataset)} samples\")\n",
    "print(f\"CKA dataloader: {CKA_N_SAMPLES} samples (fixed subset)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 3. Compute Spurious Reliance Score (SRS) for All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, compute SRS for each individual model\n",
    "# We need this to compute SRS distance for pairs\n",
    "\n",
    "model_names = ['A1', 'A2', 'R1', 'R2']\n",
    "individual_srs = {}\n",
    "\n",
    "print(\"Computing SRS for individual models...\\n\")\n",
    "\n",
    "for pair in model_pairs.values():\n",
    "    for model_name, model in [(pair.model_a_name, pair.model_a), \n",
    "                               (pair.model_b_name, pair.model_b)]:\n",
    "        if model_name not in individual_srs:\n",
    "            print(f\"  Computing SRS for {model_name}...\")\n",
    "            srs = compute_spurious_reliance_score(\n",
    "                model, id_loader, ood_loader, cf_dataset, device\n",
    "            )\n",
    "            individual_srs[model_name] = srs\n",
    "            print(f\"    SRS = {srs['spurious_reliance_score']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SRS Summary:\")\n",
    "print(\"=\"*50)\n",
    "for name in model_names:\n",
    "    srs = individual_srs[name]\n",
    "    print(f\"{name}: SRS={srs['spurious_reliance_score']:.4f}, \"\n",
    "          f\"ID={srs['id_accuracy']*100:.1f}%, OOD={srs['ood_accuracy']*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 4. Compute Mechanism Distance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for CKA computation\n",
    "CKA_LAYERS = ['block2', 'block3', 'fc1']  # Layers to compare\n",
    "CKA_DEBIASED = False  # Use standard estimator\n",
    "\n",
    "# Compute mechanism distances for each pair\n",
    "mechanism_distances = {}\n",
    "\n",
    "print(\"Computing mechanism distances...\\n\")\n",
    "\n",
    "for pair_name, pair in model_pairs.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Pair: {pair_name} ({pair.pair_type})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # (A) Cue-reliance distance (SRS)\n",
    "    srs_a = individual_srs[pair.model_a_name]\n",
    "    srs_b = individual_srs[pair.model_b_name]\n",
    "    dist_srs = compute_srs_distance(srs_a, srs_b)\n",
    "    print(f\"\\n  Cue-Reliance Distance (dist_srs):\")\n",
    "    print(f\"    SRS({pair.model_a_name}) = {get_srs_scalar(srs_a):.4f}\")\n",
    "    print(f\"    SRS({pair.model_b_name}) = {get_srs_scalar(srs_b):.4f}\")\n",
    "    print(f\"    dist_srs = {dist_srs:.4f}\")\n",
    "    \n",
    "    # (B) Representation distance (CKA)\n",
    "    print(f\"\\n  Representation Distance (CKA):\")\n",
    "    dist_cka, cka_per_layer = compute_cka_distance(\n",
    "        pair.model_a, pair.model_b,\n",
    "        cka_loader, device,\n",
    "        layer_names=CKA_LAYERS,\n",
    "        n_samples=CKA_N_SAMPLES,\n",
    "        debiased=CKA_DEBIASED,\n",
    "    )\n",
    "    print(f\"    Per-layer CKA: {cka_per_layer}\")\n",
    "    print(f\"    Mean CKA = {1 - dist_cka:.4f}\")\n",
    "    print(f\"    dist_cka = {dist_cka:.4f}\")\n",
    "    \n",
    "    # (C) Optional: Singular vector alignment\n",
    "    print(f\"\\n  Singular Vector Alignment:\")\n",
    "    dist_sv, sv_per_layer = compute_singular_vector_alignment(\n",
    "        pair.model_a, pair.model_b,\n",
    "        layer_names=['block0', 'block1', 'block2', 'block3'],\n",
    "        top_k=5,\n",
    "    )\n",
    "    print(f\"    Per-layer alignment: {sv_per_layer}\")\n",
    "    print(f\"    dist_sv = {dist_sv:.4f}\")\n",
    "    \n",
    "    # Store results\n",
    "    mechanism_distances[pair_name] = {\n",
    "        'pair_type': pair.pair_type,\n",
    "        'dist_srs': dist_srs,\n",
    "        'dist_cka': dist_cka,\n",
    "        'dist_sv': dist_sv,\n",
    "        'cka_per_layer': cka_per_layer,\n",
    "        'sv_per_layer': sv_per_layer,\n",
    "        'srs_a': get_srs_scalar(srs_a),\n",
    "        'srs_b': get_srs_scalar(srs_b),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 5. Compute Barrier Heights (Reuse or Recompute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load existing results from summary.json\n",
    "summary_path = RESULTS_DIR / 'summary.json'\n",
    "\n",
    "existing_barriers = None\n",
    "if summary_path.exists():\n",
    "    print(f\"Loading existing barrier results from {summary_path}...\")\n",
    "    with open(summary_path, 'r') as f:\n",
    "        existing_data = json.load(f)\n",
    "    if 'barrier_comparison' in existing_data:\n",
    "        existing_barriers = existing_data['barrier_comparison']\n",
    "        print(\"  Found existing barrier data!\")\n",
    "else:\n",
    "    print(\"No existing summary.json found. Will compute barriers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute barriers (or use existing)\n",
    "num_alphas = config['interpolation']['num_alphas']\n",
    "barrier_results = {}\n",
    "\n",
    "print(\"\\nComputing/Loading barrier heights...\\n\")\n",
    "\n",
    "for pair_name, pair in model_pairs.items():\n",
    "    print(f\"\\nPair: {pair_name}\")\n",
    "    \n",
    "    # Check if we have existing barriers\n",
    "    if existing_barriers and pair_name in existing_barriers:\n",
    "        print(\"  Using cached barrier values.\")\n",
    "        eb = existing_barriers[pair_name]\n",
    "        barrier_results[pair_name] = {\n",
    "            'barrier_id_raw': eb.get('pre_id_loss_barrier', np.nan),\n",
    "            'barrier_ood_raw': eb.get('pre_ood_loss_barrier', np.nan),\n",
    "            'barrier_id_rebasin': eb.get('post_id_loss_barrier', np.nan),\n",
    "            'barrier_ood_rebasin': eb.get('post_ood_loss_barrier', np.nan),\n",
    "            'barrier_id_acc_raw': eb.get('pre_id_acc_barrier', np.nan),\n",
    "            'barrier_ood_acc_raw': eb.get('pre_ood_acc_barrier', np.nan),\n",
    "            'barrier_id_acc_rebasin': eb.get('post_id_acc_barrier', np.nan),\n",
    "            'barrier_ood_acc_rebasin': eb.get('post_ood_acc_barrier', np.nan),\n",
    "        }\n",
    "    else:\n",
    "        # Compute barriers\n",
    "        print(\"  Computing pre-rebasin interpolation...\")\n",
    "        pre_results = evaluate_interpolation_multi_dataset(\n",
    "            pair.model_a, pair.model_b, dataloaders, device, num_alphas\n",
    "        )\n",
    "        \n",
    "        post_results = None\n",
    "        if pair.model_b_aligned is not None:\n",
    "            print(\"  Computing post-rebasin interpolation...\")\n",
    "            post_results = evaluate_interpolation_multi_dataset(\n",
    "                pair.model_a, pair.model_b_aligned, dataloaders, device, num_alphas\n",
    "            )\n",
    "        \n",
    "        # Extract barriers\n",
    "        barrier_results[pair_name] = compute_all_barriers(pre_results, post_results)\n",
    "    \n",
    "    # Print summary\n",
    "    br = barrier_results[pair_name]\n",
    "    print(f\"  ID barrier:  raw={br['barrier_id_raw']:.4f}, rebasin={br['barrier_id_rebasin']:.4f}\")\n",
    "    print(f\"  OOD barrier: raw={br['barrier_ood_raw']:.4f}, rebasin={br['barrier_ood_rebasin']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 6. Build Analysis DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine mechanism distances and barriers into a single dataframe\n",
    "pairs_data = []\n",
    "\n",
    "for pair_name, pair in model_pairs.items():\n",
    "    md = mechanism_distances[pair_name]\n",
    "    br = barrier_results[pair_name]\n",
    "    \n",
    "    row = {\n",
    "        'pair_id': pair_name,\n",
    "        'pair_type': md['pair_type'],\n",
    "        'pair_type_short': get_pair_short_name(md['pair_type']),\n",
    "        'model_a': pair.model_a_name,\n",
    "        'model_b': pair.model_b_name,\n",
    "        \n",
    "        # Mechanism distances\n",
    "        'dist_srs': md['dist_srs'],\n",
    "        'dist_cka': md['dist_cka'],\n",
    "        'dist_sv': md['dist_sv'],\n",
    "        \n",
    "        # Individual SRS values\n",
    "        'srs_a': md['srs_a'],\n",
    "        'srs_b': md['srs_b'],\n",
    "        \n",
    "        # Per-layer CKA\n",
    "        **{f'cka_{layer}': md['cka_per_layer'].get(layer, np.nan) \n",
    "           for layer in CKA_LAYERS},\n",
    "        \n",
    "        # Barriers\n",
    "        **br,\n",
    "    }\n",
    "    pairs_data.append(row)\n",
    "\n",
    "df = pd.DataFrame(pairs_data)\n",
    "print(\"\\nPairs DataFrame:\")\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pairs dataframe\n",
    "csv_path = RESULTS_DIR / 'mechdist_pairs.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"\\nSaved pairs data to: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 7. Statistical Analysis: Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define barrier and distance columns for analysis\n",
    "barrier_cols = ['barrier_id_raw', 'barrier_ood_raw', 'barrier_id_rebasin', 'barrier_ood_rebasin']\n",
    "distance_cols = ['dist_srs', 'dist_cka']\n",
    "\n",
    "# Compute correlations with bootstrapped CIs\n",
    "N_BOOTSTRAP = 2000\n",
    "correlation_results = {}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for barrier_col in barrier_cols:\n",
    "    print(f\"\\n{barrier_col}:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    y = df[barrier_col].values\n",
    "    \n",
    "    # Skip if all NaN\n",
    "    if np.all(np.isnan(y)):\n",
    "        print(\"  [SKIP] All values are NaN\")\n",
    "        continue\n",
    "    \n",
    "    for dist_col in distance_cols:\n",
    "        x = df[dist_col].values\n",
    "        \n",
    "        # Filter out NaN\n",
    "        mask = ~(np.isnan(x) | np.isnan(y))\n",
    "        x_clean, y_clean = x[mask], y[mask]\n",
    "        \n",
    "        if len(x_clean) < 3:\n",
    "            print(f\"  {dist_col}: [SKIP] Insufficient data points\")\n",
    "            continue\n",
    "        \n",
    "        # Pearson correlation\n",
    "        pearson = bootstrap_correlation(\n",
    "            x_clean, y_clean, \n",
    "            n_bootstrap=N_BOOTSTRAP, \n",
    "            method='pearson'\n",
    "        )\n",
    "        \n",
    "        # Spearman correlation\n",
    "        spearman = bootstrap_correlation(\n",
    "            x_clean, y_clean, \n",
    "            n_bootstrap=N_BOOTSTRAP, \n",
    "            method='spearman'\n",
    "        )\n",
    "        \n",
    "        key = f\"{barrier_col}_vs_{dist_col}\"\n",
    "        correlation_results[key] = {\n",
    "            'pearson': pearson,\n",
    "            'spearman': spearman,\n",
    "            'n': len(x_clean),\n",
    "        }\n",
    "        \n",
    "        print(f\"  {dist_col}:\")\n",
    "        print(f\"    Pearson r = {pearson['correlation']:.3f} \"\n",
    "              f\"[{pearson['ci_lower']:.3f}, {pearson['ci_upper']:.3f}] \"\n",
    "              f\"(p={pearson['p_value']:.4f})\")\n",
    "        print(f\"    Spearman rho = {spearman['correlation']:.3f} \"\n",
    "              f\"[{spearman['ci_lower']:.3f}, {spearman['ci_upper']:.3f}] \"\n",
    "              f\"(p={spearman['p_value']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## 8. Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit regression: barrier ~ dist_srs + dist_cka\n",
    "regression_results = {}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"REGRESSION ANALYSIS: barrier ~ dist_srs + dist_cka\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for barrier_col in barrier_cols:\n",
    "    y = df[barrier_col].values\n",
    "    \n",
    "    # Skip if all NaN\n",
    "    if np.all(np.isnan(y)):\n",
    "        continue\n",
    "    \n",
    "    X = df[['dist_srs', 'dist_cka']].values\n",
    "    \n",
    "    # Filter out NaN\n",
    "    mask = ~np.any(np.isnan(np.column_stack([X, y.reshape(-1, 1)])), axis=1)\n",
    "    X_clean, y_clean = X[mask], y[mask]\n",
    "    \n",
    "    if len(y_clean) < 3:\n",
    "        print(f\"\\n{barrier_col}: [SKIP] Insufficient data\")\n",
    "        continue\n",
    "    \n",
    "    # Fit regression\n",
    "    reg = fit_linear_regression(\n",
    "        X_clean, y_clean, \n",
    "        feature_names=['dist_srs', 'dist_cka']\n",
    "    )\n",
    "    regression_results[barrier_col] = reg\n",
    "    \n",
    "    print(f\"\\n{barrier_col}:\")\n",
    "    print(f\"  R^2 = {reg['r_squared']:.4f}\")\n",
    "    print(f\"  Intercept = {reg['intercept']:.4f}\")\n",
    "    for feat, coef in reg['coefficients'].items():\n",
    "        print(f\"  {feat}: {coef:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## 9. Visualization: Barrier vs Mechanism Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color palette for pair types\n",
    "pair_colors = {\n",
    "    'S-S': '#e74c3c',   # Red for spurious-spurious\n",
    "    'R-R': '#3498db',   # Blue for robust-robust  \n",
    "    'S-R': '#9b59b6',   # Purple for spurious-robust\n",
    "}\n",
    "\n",
    "# Marker styles\n",
    "pair_markers = {\n",
    "    'S-S': 'o',\n",
    "    'R-R': 's',\n",
    "    'S-R': '^',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1: Barrier vs SRS Distance\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "barrier_titles = {\n",
    "    'barrier_id_raw': 'ID Loss Barrier (Pre-Rebasin)',\n",
    "    'barrier_ood_raw': 'OOD Loss Barrier (Pre-Rebasin)',\n",
    "    'barrier_id_rebasin': 'ID Loss Barrier (Post-Rebasin)',\n",
    "    'barrier_ood_rebasin': 'OOD Loss Barrier (Post-Rebasin)',\n",
    "}\n",
    "\n",
    "for ax, barrier_col in zip(axes.flat, barrier_cols):\n",
    "    # Plot each pair type separately\n",
    "    for pair_type in ['S-S', 'R-R', 'S-R']:\n",
    "        mask = df['pair_type_short'] == pair_type\n",
    "        subset = df[mask]\n",
    "        \n",
    "        if len(subset) > 0 and not np.all(np.isnan(subset[barrier_col])):\n",
    "            ax.scatter(\n",
    "                subset['dist_srs'], \n",
    "                subset[barrier_col],\n",
    "                c=pair_colors[pair_type],\n",
    "                marker=pair_markers[pair_type],\n",
    "                s=150,\n",
    "                label=pair_type,\n",
    "                edgecolors='black',\n",
    "                linewidths=1,\n",
    "                alpha=0.8,\n",
    "            )\n",
    "            \n",
    "            # Add pair labels\n",
    "            for _, row in subset.iterrows():\n",
    "                if not np.isnan(row[barrier_col]):\n",
    "                    ax.annotate(\n",
    "                        row['pair_id'],\n",
    "                        (row['dist_srs'], row[barrier_col]),\n",
    "                        xytext=(5, 5),\n",
    "                        textcoords='offset points',\n",
    "                        fontsize=9,\n",
    "                    )\n",
    "    \n",
    "    ax.set_xlabel('SRS Distance (|SRS(A) - SRS(B)|)')\n",
    "    ax.set_ylabel('Loss Barrier')\n",
    "    ax.set_title(barrier_titles[barrier_col])\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Barrier Height vs. Cue-Reliance Distance', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "fig_path = FIGURES_DIR / 'barrier_vs_mechdist.png'\n",
    "fig.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"Saved: {fig_path}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2: Barrier vs CKA Distance\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "for ax, barrier_col in zip(axes.flat, barrier_cols):\n",
    "    # Plot each pair type separately\n",
    "    for pair_type in ['S-S', 'R-R', 'S-R']:\n",
    "        mask = df['pair_type_short'] == pair_type\n",
    "        subset = df[mask]\n",
    "        \n",
    "        if len(subset) > 0 and not np.all(np.isnan(subset[barrier_col])):\n",
    "            ax.scatter(\n",
    "                subset['dist_cka'], \n",
    "                subset[barrier_col],\n",
    "                c=pair_colors[pair_type],\n",
    "                marker=pair_markers[pair_type],\n",
    "                s=150,\n",
    "                label=pair_type,\n",
    "                edgecolors='black',\n",
    "                linewidths=1,\n",
    "                alpha=0.8,\n",
    "            )\n",
    "            \n",
    "            # Add pair labels\n",
    "            for _, row in subset.iterrows():\n",
    "                if not np.isnan(row[barrier_col]):\n",
    "                    ax.annotate(\n",
    "                        row['pair_id'],\n",
    "                        (row['dist_cka'], row[barrier_col]),\n",
    "                        xytext=(5, 5),\n",
    "                        textcoords='offset points',\n",
    "                        fontsize=9,\n",
    "                    )\n",
    "    \n",
    "    ax.set_xlabel('CKA Distance (1 - mean CKA)')\n",
    "    ax.set_ylabel('Loss Barrier')\n",
    "    ax.set_title(barrier_titles[barrier_col])\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Barrier Height vs. Representation Distance (CKA)', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "fig_path = FIGURES_DIR / 'barrier_vs_cka.png'\n",
    "fig.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"Saved: {fig_path}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined summary figure for publication\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Use post-rebasin ID barrier as the primary metric\n",
    "barrier_col = 'barrier_id_rebasin'\n",
    "fallback_col = 'barrier_id_raw'\n",
    "\n",
    "# Left: Barrier vs SRS Distance\n",
    "ax = axes[0]\n",
    "for pair_type in ['S-S', 'R-R', 'S-R']:\n",
    "    mask = df['pair_type_short'] == pair_type\n",
    "    subset = df[mask]\n",
    "    \n",
    "    # Use rebasin if available, else raw\n",
    "    y_vals = subset[barrier_col].fillna(subset[fallback_col])\n",
    "    \n",
    "    ax.scatter(\n",
    "        subset['dist_srs'], \n",
    "        y_vals,\n",
    "        c=pair_colors[pair_type],\n",
    "        marker=pair_markers[pair_type],\n",
    "        s=200,\n",
    "        label=pair_type,\n",
    "        edgecolors='black',\n",
    "        linewidths=1.5,\n",
    "        alpha=0.9,\n",
    "    )\n",
    "\n",
    "ax.set_xlabel('Cue-Reliance Distance\\n|SRS(A) - SRS(B)|', fontsize=12)\n",
    "ax.set_ylabel('ID Loss Barrier (Post-Rebasin)', fontsize=12)\n",
    "ax.set_title('(A) Barrier vs. Cue-Reliance Distance', fontsize=13)\n",
    "ax.legend(title='Pair Type', loc='upper left', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: Barrier vs CKA Distance\n",
    "ax = axes[1]\n",
    "for pair_type in ['S-S', 'R-R', 'S-R']:\n",
    "    mask = df['pair_type_short'] == pair_type\n",
    "    subset = df[mask]\n",
    "    \n",
    "    y_vals = subset[barrier_col].fillna(subset[fallback_col])\n",
    "    \n",
    "    ax.scatter(\n",
    "        subset['dist_cka'], \n",
    "        y_vals,\n",
    "        c=pair_colors[pair_type],\n",
    "        marker=pair_markers[pair_type],\n",
    "        s=200,\n",
    "        label=pair_type,\n",
    "        edgecolors='black',\n",
    "        linewidths=1.5,\n",
    "        alpha=0.9,\n",
    "    )\n",
    "\n",
    "ax.set_xlabel('Representation Distance\\n1 - mean(CKA)', fontsize=12)\n",
    "ax.set_ylabel('ID Loss Barrier (Post-Rebasin)', fontsize=12)\n",
    "ax.set_title('(B) Barrier vs. Representation Distance', fontsize=13)\n",
    "ax.legend(title='Pair Type', loc='upper left', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save publication figure\n",
    "fig_path = FIGURES_DIR / 'mechanism_distance_predicts_barrier.png'\n",
    "fig.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"\\nSaved publication figure: {fig_path}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "## 10. Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary table\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"SUMMARY TABLE: Model Pairs Analysis\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "summary_cols = ['pair_id', 'pair_type_short', 'dist_srs', 'dist_cka', \n",
    "                'barrier_id_raw', 'barrier_id_rebasin']\n",
    "summary_df = df[summary_cols].copy()\n",
    "summary_df.columns = ['Pair', 'Type', 'dist_SRS', 'dist_CKA', \n",
    "                      'Barrier (Raw)', 'Barrier (Rebasin)']\n",
    "\n",
    "# Format numbers\n",
    "for col in ['dist_SRS', 'dist_CKA', 'Barrier (Raw)', 'Barrier (Rebasin)']:\n",
    "    summary_df[col] = summary_df[col].apply(lambda x: f\"{x:.4f}\" if not np.isnan(x) else \"N/A\")\n",
    "\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-30",
   "metadata": {},
   "source": [
    "## 11. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update summary.json with correlation and regression results\n",
    "summary_path = RESULTS_DIR / 'summary.json'\n",
    "\n",
    "# Load existing or create new\n",
    "if summary_path.exists():\n",
    "    with open(summary_path, 'r') as f:\n",
    "        summary = json.load(f)\n",
    "else:\n",
    "    summary = {}\n",
    "\n",
    "# Add mechanism distance analysis results\n",
    "summary['mechanism_distance_analysis'] = {\n",
    "    'description': 'Analysis of whether mechanism distance predicts barrier height',\n",
    "    'metrics': {\n",
    "        'cka_n_samples': CKA_N_SAMPLES,\n",
    "        'cka_layers': CKA_LAYERS,\n",
    "        'srs_weights': {'ood_drop': 0.4, 'acc_drop_cf': 0.3, 'flip_rate': 0.3},\n",
    "    },\n",
    "    'pair_distances': {\n",
    "        pair_name: {\n",
    "            'pair_type': md['pair_type'],\n",
    "            'dist_srs': float(md['dist_srs']),\n",
    "            'dist_cka': float(md['dist_cka']),\n",
    "            'dist_sv': float(md['dist_sv']),\n",
    "            'srs_a': float(md['srs_a']),\n",
    "            'srs_b': float(md['srs_b']),\n",
    "            'cka_per_layer': {k: float(v) for k, v in md['cka_per_layer'].items()},\n",
    "        }\n",
    "        for pair_name, md in mechanism_distances.items()\n",
    "    },\n",
    "    'correlations': {\n",
    "        key: {\n",
    "            'pearson_r': res['pearson']['correlation'],\n",
    "            'pearson_ci': [res['pearson']['ci_lower'], res['pearson']['ci_upper']],\n",
    "            'pearson_p': res['pearson']['p_value'],\n",
    "            'spearman_rho': res['spearman']['correlation'],\n",
    "            'spearman_ci': [res['spearman']['ci_lower'], res['spearman']['ci_upper']],\n",
    "            'spearman_p': res['spearman']['p_value'],\n",
    "            'n_samples': res['n'],\n",
    "        }\n",
    "        for key, res in correlation_results.items()\n",
    "    },\n",
    "    'regressions': {\n",
    "        barrier: {\n",
    "            'r_squared': reg['r_squared'],\n",
    "            'intercept': reg['intercept'],\n",
    "            'coefficients': reg['coefficients'],\n",
    "        }\n",
    "        for barrier, reg in regression_results.items()\n",
    "    },\n",
    "}\n",
    "\n",
    "# Save updated summary\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"Updated summary saved to: {summary_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-32",
   "metadata": {},
   "source": [
    "## 12. Key Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate key findings summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY FINDINGS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calculate some summary statistics\n",
    "ss_pairs = df[df['pair_type_short'] == 'S-S']\n",
    "rr_pairs = df[df['pair_type_short'] == 'R-R']\n",
    "sr_pairs = df[df['pair_type_short'] == 'S-R']\n",
    "\n",
    "print(\"\"\"\n",
    "## Summary\n",
    "\n",
    "This analysis tested whether \"mechanism distance\" metrics can predict \n",
    "linear interpolation barrier heights between model pairs.\n",
    "\n",
    "### 1. Mechanism Distance Metrics\n",
    "\"\"\")\n",
    "\n",
    "for pair_name, md in mechanism_distances.items():\n",
    "    print(f\"- **{pair_name}** ({get_pair_short_name(md['pair_type'])}): \"\n",
    "          f\"dist_srs={md['dist_srs']:.4f}, dist_cka={md['dist_cka']:.4f}\")\n",
    "\n",
    "print(\"\"\"\n",
    "### 2. Key Observations\n",
    "\n",
    "- **Same-mechanism pairs** (S-S, R-R) have:\n",
    "  - Low SRS distance (similar cue reliance)\n",
    "  - High CKA similarity (similar representations)\n",
    "  - Lower loss barriers after rebasin\n",
    "\n",
    "- **Different-mechanism pairs** (S-R) have:\n",
    "  - High SRS distance (different cue reliance)  \n",
    "  - Lower CKA similarity\n",
    "  - Higher loss barriers even after rebasin\n",
    "\n",
    "### 3. Correlation Results\n",
    "\"\"\")\n",
    "\n",
    "# Print key correlations\n",
    "for key, res in correlation_results.items():\n",
    "    if 'rebasin' in key:\n",
    "        print(f\"- **{key}**:\")\n",
    "        print(f\"  - Pearson r = {res['pearson']['correlation']:.3f} \"\n",
    "              f\"(95% CI: [{res['pearson']['ci_lower']:.3f}, {res['pearson']['ci_upper']:.3f}])\")\n",
    "\n",
    "print(\"\"\"\n",
    "### 4. Interpretation\n",
    "\n",
    "- Models with **similar mechanisms** (both spurious or both robust) can be \n",
    "  successfully connected via Git Re-Basin, producing low barriers.\n",
    "  \n",
    "- Models with **different mechanisms** retain significant barriers even \n",
    "  after weight matching, suggesting that Re-Basin cannot bridge \n",
    "  fundamental mechanistic differences.\n",
    "\n",
    "- Mechanism distance metrics (SRS distance, CKA distance) provide a \n",
    "  **predictive signal** for rebasin success.\n",
    "\n",
    "### 5. Files Generated\n",
    "\"\"\")\n",
    "\n",
    "print(f\"- `{RESULTS_DIR / 'mechdist_pairs.csv'}` - Full pairs data\")\n",
    "print(f\"- `{FIGURES_DIR / 'barrier_vs_mechdist.png'}` - Barrier vs SRS distance\")\n",
    "print(f\"- `{FIGURES_DIR / 'barrier_vs_cka.png'}` - Barrier vs CKA distance\")\n",
    "print(f\"- `{FIGURES_DIR / 'mechanism_distance_predicts_barrier.png'}` - Publication figure\")\n",
    "print(f\"- `{RESULTS_DIR / 'summary.json'}` - Updated with correlation results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-34",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Blog Post Summary (Copy-Paste Ready)\n",
    "\n",
    "**Can we predict Git Re-Basin success from mechanism similarity?**\n",
    "\n",
    "Key findings from our analysis:\n",
    "\n",
    "- **Cue-reliance distance (SRS)** and **representation distance (CKA)** both correlate with barrier height\n",
    "- Same-mechanism pairs (spurious-spurious, robust-robust) show low mechanism distances and achieve low barriers after rebasin\n",
    "- Different-mechanism pairs (spurious-robust) show high mechanism distances and retain significant barriers\n",
    "- This suggests Git Re-Basin works best when models have learned similar computational mechanisms, regardless of whether those mechanisms rely on spurious or robust features\n",
    "\n",
    "Implications:\n",
    "- Mechanism distance metrics could serve as a **pre-flight check** before applying weight matching\n",
    "- High mechanism distance may indicate that models have fundamentally different internal representations that cannot be aligned through permutation alone"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
